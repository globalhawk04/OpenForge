# FILE: app/services/vision_service.py
import google.generativeai as genai
import PIL.Image
import requests
from io import BytesIO
from app.config import settings
import json
import re

# Configure API (unchanged)
if settings.GOOGLE_API_KEY:
    genai.configure(api_key=settings.GOOGLE_API_KEY)

# =====================================================================
# REFACTORED AND GENERALIZED FUNCTION FOR TASK 2.2
# =====================================================================
async def analyze_image_for_specs(image_url: str, part_type: str, dynamic_prompt_object: dict) -> dict | None:
    """
    Downloads an image and asks Gemini Vision to extract specs using a dynamically generated prompt.

    This function is now a generic executor. It has no specific knowledge of component
    types. It relies entirely on the prompt generated by the "Vision Prompt Engineer" AI.

    Args:
        image_url: The URL of the technical diagram/product photo.
        part_type: The name of the part category (for logging purposes).
        dynamic_prompt_object: The object from generate_vision_prompt containing
                               'prompt_text' and 'json_schema'.

    Returns:
        A dictionary of the extracted specifications, or None on failure.
    """
    print(f"üëÅÔ∏è  Vision AI Analyzing ({part_type}): {image_url}")
    
    # 1. Download Image (unchanged)
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(image_url, headers=headers, timeout=15)
        response.raise_for_status()
        img = PIL.Image.open(BytesIO(response.content))
    except Exception as e:
        print(f"   ‚ùå Image Download Error: {e}")
        return {"error": "download_failed", "details": str(e)}

    # 2. Construct the full prompt from the dynamic components
    prompt_text = dynamic_prompt_object.get("prompt_text", "Analyze the image.")
    json_schema = dynamic_prompt_object.get("json_schema", "{}")

    # Combine them into a final instruction for the vision model
    full_prompt = f"""
    {prompt_text}

    Your entire response MUST be ONLY the following JSON object, adhering strictly to the schema. Do not include markdown formatting or any other text.
    
    SCHEMA:
    {json_schema}
    """

    # 3. Call Gemini Vision
    try:
        model = genai.GenerativeModel('gemini-2.5-pro') 
        response = await model.generate_content_async([full_prompt, img])
        
        raw_text = response.text
        if not raw_text:
            return {"error": "empty_response"}

        # Use the same robust JSON parsing from ai_service
        match = re.search(r"```(json)?\s*({.*})\s*```", raw_text, re.DOTALL)
        json_str = match.group(2) if match else raw_text
        if not match:
            start, end = raw_text.find("{"), raw_text.rfind("}") + 1
            if start != -1 and end != -1:
                json_str = raw_text[start:end]

        # Cleanup common AI syntax errors before parsing
        json_str = json_str.replace("True", "true").replace("False", "false").replace("None", "null").replace("'", '"')
        
        parsed_json = json.loads(json_str)
        print(f"   ‚úÖ Vision AI extracted: {parsed_json}")
        return parsed_json
        
    except json.JSONDecodeError as e:
        print(f"   ‚ùå Vision JSON Parse Error: {e}. Raw Output: {raw_text}")
        return {"error": "json_parse_error", "raw_output": raw_text}
    except Exception as e:
        print(f"   ‚ùå Vision Processing Error: {e}")
        return {"error": "vision_api_error", "details": str(e)}